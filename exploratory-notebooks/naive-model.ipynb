{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c392a41a-0ec9-48da-a7b5-0b453e5a8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ece2dc3-1470-4b5d-b7bb-6802a86e8d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    # Convert the 'timestamp' column to datetime format and set it as the index\n",
    "    data['millisUTC'] = pd.to_datetime(data['millisUTC'])\n",
    "    \n",
    "    data.set_index('millisUTC', inplace=True)\n",
    "    \n",
    "    # Resample dataset to 30 minutes\n",
    "    data = data.resample(\"30T\", label=\"right\").mean()\n",
    "\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    # Need a better way to handle missing values\n",
    "    data['price'] = data['price'].ffill()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df7c89bc-01b0-45f8-8f2a-e341150f93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "    # Split the data into training and testing sets\n",
    "    train_size = int(0.8 * len(data))\n",
    "    train_data = data.iloc[:train_size]\n",
    "    test_data = data.iloc[train_size:]\n",
    "\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8738b3cb-e053-4398-87dd-60d8984443e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveModel(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, value=3.083333):\n",
    "        self.value = value\n",
    "\n",
    "    def fit(self, X=data, y=None):\n",
    "        return self\n",
    "\n",
    "    def predict(self, data):\n",
    "        return np.array([self.value] * len(data))\n",
    "\n",
    "naive_model = NaiveModel()\n",
    "naive_model = naive_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd7b37-800f-4cb7-ac67-a556317e9b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_name, file_dir=\"/workspaces/comed-pricing/models/\"):\n",
    "    with open(f\"{file_dir}/{file_name}\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "def load_model(file_name, file_dir=\"/workspaces/comed-pricing/models/\"):\n",
    "    with open(f\"{file_dir}/{file_name}\", 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ca993c-0f24-48bd-9fae-56decd2bc4bb",
   "metadata": {},
   "source": [
    "# Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3978732e-58f6-479f-af4d-0b3f0d225574",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/workspaces/comed-pricing/data/raw_data.csv\")\n",
    "\n",
    "# This is a bit strange to do\n",
    "# We're reading the dataset using pandas, then splitting it, and then creating distributed datasets from pandas\n",
    "train_data, test_data = split_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c58ff17d-ac38-46ce-96a7-4ce05f03cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ray.data.from_pandas(train_data)\n",
    "test_ds = ray.data.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "401c7295-f9d6-45b5-9d9b-fc22e5b50e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 17:13:31,662\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(preprocess)]\n",
      "2023-09-05 17:13:31,663\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-05 17:13:31,664\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'price': 2.0500000000000003}\n"
     ]
    }
   ],
   "source": [
    "sample_ds = train_ds.map_batches(\n",
    "    preprocess,\n",
    "    batch_format=\"pandas\"\n",
    ")\n",
    "sample_ds.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e8d360-e221-4658-8213-48853c6e7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(num_samples=None):\n",
    "    ds "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
