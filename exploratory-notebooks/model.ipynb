{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce079fa2-322f-40a8-9c8a-7ee7691c3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ray.data.preprocessor import Preprocessor\n",
    "import ray\n",
    "\n",
    "\n",
    "DATASET_LOC = \"/workspaces/comed-pricing/data/raw_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3860e70-ad36-458d-a86a-d42507458f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y_splits(data, columns, targets, n_steps_in, n_steps_out, gap, include_target_in_X=False):\n",
    "    \"\"\"This function converts a dataframe into X and Y sequences for training\"\"\"\n",
    "\n",
    "    # Include target column\n",
    "    if include_target_in_X:\n",
    "        columns = columns + targets\n",
    "\n",
    "    complete_x_array = data[columns].to_numpy()\n",
    "    complete_y_array = data[targets].to_numpy()\n",
    "\n",
    "    upper_bound = len(data) - (n_steps_in + n_steps_out + gap)\n",
    "    \n",
    "    # Pre-allocate arrays for performance\n",
    "    X_shape = (upper_bound, n_steps_in, complete_x_array.shape[1])\n",
    "    y_shape = (upper_bound, n_steps_out, complete_y_array.shape[1])\n",
    "\n",
    "    X_arrays = np.empty(X_shape, dtype=np.float32)\n",
    "    y_arrays = np.empty(y_shape, dtype=np.float32)\n",
    "\n",
    "    for index in range(upper_bound):\n",
    "        starting_X_index = index\n",
    "        ending_X_index = starting_X_index + n_steps_in\n",
    "        starting_y_index = ending_X_index + gap\n",
    "        ending_y_index = starting_y_index + n_steps_out\n",
    "\n",
    "        X_arrays[index] = complete_x_array[starting_X_index: ending_X_index]\n",
    "        y_arrays[index] = complete_y_array[starting_y_index: ending_y_index]\n",
    "\n",
    "    return torch.tensor(X_arrays, dtype=torch.float32), torch.tensor(y_arrays, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def preprocess(data, columns, targets, n_steps_in, n_steps_out, gap, include_target_in_X=False, resample_units=None):\n",
    "    # reset_index\n",
    "     # Convert the 'timestamp' column to datetime format and set it as the index\n",
    "    data['millisUTC'] = pd.to_datetime(data['millisUTC'])\n",
    "    data.set_index('millisUTC', inplace=True)\n",
    "\n",
    "    # Resample dataset\n",
    "    if resample_units is not None:\n",
    "        data = data.resample(resample_units, label=\"right\").mean()\n",
    "\n",
    "    # Need a better way to handle missing values\n",
    "    data['price'] = data['price'].ffill()\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    X, y = get_x_y_splits(\n",
    "        data, \n",
    "        columns=columns, \n",
    "        targets=targets, \n",
    "        n_steps_in=n_steps_in, \n",
    "        n_steps_out=n_steps_out, \n",
    "        gap=gap, \n",
    "        include_target_in_X=include_target_in_X\n",
    "    )\n",
    "    \n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc00e91-9b46-4706-9604-6a4e0338ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=42):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    eval(\"setattr(torch.backends.cudnn, 'deterministic', True)\")\n",
    "    eval(\"setattr(torch.backends.cudnn, 'benchmark', False)\")\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "369f512c-4ace-4fb2-bb4f-86891e92d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(num_samples=None):\n",
    "    ds = ray.data.read_csv(DATASET_LOC)\n",
    "    ds = ds.random_shuffle(seed=1234)\n",
    "    ds = ray.data.from_items(ds.take(num_samples)) if num_samples else ds\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d264df-609e-412d-b1fd-902f799eaf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPreprocessor(Preprocessor):\n",
    "    def _fit(self, ds):\n",
    "        return self\n",
    "\n",
    "    def _transform_pandas(self, batch):\n",
    "        return preprocess(\n",
    "            batch,\n",
    "            resample_units=\"60T\", # Resample values by 60 minutes\n",
    "            columns=['price'],\n",
    "            targets=['price'], \n",
    "            n_steps_in=5, \n",
    "            n_steps_out=10, \n",
    "            gap=60, \n",
    "            include_target_in_X=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e3c185d-ce0a-43b4-aab4-cdb1b37ec8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa0d11c-73de-4027-9767-93fb1a333574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    \"\"\"LSTM neural network\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size,  output_size=10):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X, h=None):\n",
    "        output, hidden_state = self.lstm(X, h)\n",
    "        last_hidden_state = output[:, -1]\n",
    "        output = self.linear(last_hidden_state)\n",
    "        return output, hidden_state\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def predict(self, batch):\n",
    "        self.eval()\n",
    "        z = self(batch)\n",
    "        output = self.linear(last_hidden_state)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "283d7062-a693-4811-9a29-e6582995c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air import Checkpoint, session\n",
    "from ray.air.config import CheckpointConfig, DatasetConfig, RunConfig, ScalingConfig\n",
    "import ray.train as train\n",
    "from ray.train.torch import TorchCheckpoint, TorchTrainer\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e05f8729-30b0-4677-b8d7-ebed7a8a400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(ds, batch_size, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    loss = 0.0\n",
    "    ds_generator = ds.iter_torch_batches(batch_size=batch_size)\n",
    "    for i, batch in enumerate(ds_generator):\n",
    "        optimizer.zero_grad()  # reset gradients\n",
    "        z = model(batch)  # forward pass\n",
    "        J = loss_fn(z, targets)  # define loss\n",
    "        J.backward()  # backward pass\n",
    "        optimizer.step()  # update weights\n",
    "        loss += (J.detach().item() - loss) / (i + 1)  # cumulative loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "773a0cf8-a831-4856-9e37-d5cf3819f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(ds, batch_size, model, num_classes, loss_fn):\n",
    "    \"\"\"Eval step.\"\"\"\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    y_trues, y_preds = [], []\n",
    "    ds_generator = ds.iter_torch_batches(batch_size=batch_size, collate_fn=collate_fn)\n",
    "    with torch.inference_mode():\n",
    "        for i, batch in enumerate(ds_generator):\n",
    "            z = model(batch)\n",
    "            J = loss_fn(z, z).item()\n",
    "            loss += (J - loss) / (i + 1)\n",
    "            y_trues.extend(batch[\"targets\"].cpu().numpy())\n",
    "            y_preds.extend(torch.argmax(z, dim=1).cpu().numpy())\n",
    "    return loss, np.vstack(y_trues), np.vstack(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2119e891-d9d5-49e3-8d82-4223f0b2dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_loop_per_worker(config):\n",
    "    # Hyperparameters\n",
    "    dropout_p = config[\"dropout_p\"]\n",
    "    lr = config[\"lr\"]\n",
    "    lr_factor = config[\"lr_factor\"]\n",
    "    lr_patience = config[\"lr_patience\"]\n",
    "    num_epochs = config[\"num_epochs\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    input_size = config[\"input_size\"]\n",
    "    hidden_size = config[\"hidden_size\"]\n",
    "\n",
    "    # Get datasets\n",
    "    set_seeds()\n",
    "    train_ds = session.get_dataset_shard(\"train\")\n",
    "    val_ds = session.get_dataset_shard(\"val\")\n",
    "\n",
    "    # Model\n",
    "    model =  LSTM(input_size=input_size, hidden_size=hidden_size)\n",
    "    model = train.torch.prepare_model(model)\n",
    "\n",
    "    # Training components\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=lr_factor, patience=lr_patience)\n",
    "\n",
    "    # Training\n",
    "    batch_size_per_worker = batch_size // session.get_world_size()\n",
    "    for epoch in range(num_epochs):\n",
    "        # Step\n",
    "        train_loss = train_step(train_ds, batch_size_per_worker, model, num_classes, loss_fn, optimizer)\n",
    "        val_loss, _, _ = eval_step(val_ds, batch_size_per_worker, model, num_classes, loss_fn)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Checkpoint\n",
    "        metrics = dict(epoch=epoch, lr=optimizer.param_groups[0][\"lr\"], train_loss=train_loss, val_loss=val_loss)\n",
    "        checkpoint = TorchCheckpoint.from_model(model=model)\n",
    "        session.report(metrics, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2337434a-e483-454e-9552-f5223b634c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop config\n",
    "train_loop_config = {\n",
    "    \"dropout_p\": 0.5,\n",
    "    \"lr\": 1e-4,\n",
    "    \"lr_factor\": 0.8,\n",
    "    \"lr_patience\": 3,\n",
    "    \"num_epochs\": 10,\n",
    "    \"batch_size\": 256,\n",
    "    \"input_size\": 2,\n",
    "    \"hidden_size\": 32\n",
    "}\n",
    "\n",
    "num_workers = 1  # prefer to do a few less than total available CPU (1 for head node + 1 for background tasks)\n",
    "resources_per_worker={\"CPU\": 1, \"GPU\": 0}\n",
    "\n",
    "# Scaling config\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=num_workers,\n",
    "    use_gpu=bool(resources_per_worker[\"GPU\"]),\n",
    "    resources_per_worker=resources_per_worker,\n",
    "    _max_cpu_fraction_per_node=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb46ee38-7f99-4959-aa55-60586bbb8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "    # Split the data into training and testing sets\n",
    "    train_size = int(0.8 * len(data))\n",
    "    train_data = data.iloc[:train_size]\n",
    "    test_data = data.iloc[train_size:]\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de10cfe2-c909-41e5-8d24-cbaaa300aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/workspaces/comed-pricing/data/raw_data.csv\")\n",
    "# This is a bit strange to do\n",
    "# We're reading the dataset using pandas, then splitting it, and then creating distributed datasets from pandas\n",
    "train_data, val_data = split_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9b56fff-aa74-49e9-8f04-1d62ac0282f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 19:23:59,687\tWARNING services.py:1832 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=1.77gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-09-05 19:23:59,834\tINFO worker.py:1621 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "train_ds = ray.data.from_pandas(train_data)\n",
    "val_ds = ray.data.from_pandas(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d20960-ff21-473d-81d3-7efc6d84d52d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "preprocessor = CustomPreprocessor()\n",
    "train_ds =  preprocessor.fit_transform(train_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb86afc-2128-4d64-87de-2203222bbc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25669713-c88d-4112-ab8b-d33808b93850",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(\n",
    "            train_data,\n",
    "            resample_units=\"60T\", # Resample values by 60 minutes\n",
    "            columns=['price'],\n",
    "            targets=['price'], \n",
    "            n_steps_in=5, \n",
    "            n_steps_out=10, \n",
    "            gap=60, \n",
    "            include_target_in_X=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640063e7-dad4-4f29-8dae-ae5f7f2dc967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
