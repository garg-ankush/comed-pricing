{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce079fa2-322f-40a8-9c8a-7ee7691c3397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 11:07:39,361\tINFO worker.py:1621 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ray.data.preprocessor import Preprocessor\n",
    "import ray\n",
    "\n",
    "\n",
    "DATASET_LOC = \"/Users/ankushgarg/Desktop/projects/comed-pricing/data/raw_data.csv\"\n",
    "HOLDOUT_LOC = \"/Users/ankushgarg/Desktop/projects/comed-pricing/data/holdout.csv\"\n",
    "\n",
    "# Initialize Ray\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "num_workers = 6  # prefer to do a few less than total available CPU (1 for head node + 1 for background tasks)\n",
    "resources_per_worker={\"CPU\": 1, \"GPU\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3860e70-ad36-458d-a86a-d42507458f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y_splits(data, columns, targets, n_steps_in, n_steps_out, gap, include_target_in_X=False):\n",
    "    \"\"\"This function converts a dataframe into X and Y sequences for training\"\"\"\n",
    "\n",
    "    # Include target column\n",
    "    if include_target_in_X:\n",
    "        columns = columns + targets\n",
    "\n",
    "    complete_x_array = data[columns].to_numpy()\n",
    "    complete_y_array = data[targets].to_numpy()\n",
    "\n",
    "    upper_bound = len(data) - (n_steps_in + n_steps_out + gap)\n",
    "    \n",
    "    # Pre-allocate arrays for performance\n",
    "    X_shape = (upper_bound, n_steps_in, complete_x_array.shape[1])\n",
    "    y_shape = (upper_bound, n_steps_out, complete_y_array.shape[1])\n",
    "\n",
    "    X_arrays = np.empty(X_shape, dtype=np.float32)\n",
    "    y_arrays = np.empty(y_shape, dtype=np.float32)\n",
    "\n",
    "    for index in range(upper_bound):\n",
    "        starting_X_index = index\n",
    "        ending_X_index = starting_X_index + n_steps_in\n",
    "        starting_y_index = ending_X_index + gap\n",
    "        ending_y_index = starting_y_index + n_steps_out\n",
    "\n",
    "        X_arrays[index] = complete_x_array[starting_X_index: ending_X_index]\n",
    "        y_arrays[index] = complete_y_array[starting_y_index: ending_y_index]\n",
    "\n",
    "    return torch.tensor(X_arrays, dtype=torch.float32), torch.tensor(y_arrays, dtype=torch.float32)\n",
    "\n",
    "def get_x_y_split(data, columns, targets, n_steps_in, n_steps_out, gap, include_target_in_X = False):\n",
    "    \"\"\"This function converts a dataframe into X and Y sequences for training\"\"\"\n",
    "    # columns = [column for column in data.columns if column not in targets]\n",
    "\n",
    "    # Include target column\n",
    "    if include_target_in_X:\n",
    "        columns = columns + targets\n",
    "\n",
    "    complete_x_array = data[columns].to_numpy()\n",
    "    complete_y_array = data[targets].to_numpy()\n",
    "\n",
    "    X_arrays = []\n",
    "    y_arrays = []\n",
    "\n",
    "    upper_bound = len(data) - (n_steps_in + n_steps_out + gap)\n",
    "\n",
    "    # Loop through the entire dataset\n",
    "    for index in range(0, upper_bound):\n",
    "        # Based on parameters construct the training data made up of \n",
    "        # smaller arrays\n",
    "        starting_X_index = index\n",
    "        ending_X_index = starting_X_index + n_steps_in # number of features\n",
    "\n",
    "        starting_y_index = ending_X_index + gap\n",
    "        ending_y_index = starting_y_index + n_steps_out\n",
    "\n",
    "        individual_x_array = complete_x_array[starting_X_index: ending_X_index, :]\n",
    "        individual_y_array = complete_y_array[starting_y_index: ending_y_index, :]\n",
    "\n",
    "        X_arrays.append(individual_x_array)\n",
    "        y_arrays.append(individual_y_array)\n",
    "\n",
    "    # Convert a list of arrays into an array\n",
    "    X_array = np.array(X_arrays)\n",
    "    y_array = np.array(y_arrays)\n",
    "\n",
    "    # Flatten the array in case it's 3 dimensional\n",
    "    if len(y_array.shape) == 3:\n",
    "        y_array = np.array([individual_array.flatten() for individual_array in y_array])\n",
    "    \n",
    "    return X_array, y_array\n",
    "\n",
    "\n",
    "def preprocess(data, columns, targets, n_steps_in, n_steps_out, gap, include_target_in_X=False, resample_units=None):\n",
    "    # # reset_index\n",
    "    #  # Convert the 'timestamp' column to datetime format and set it as the index\n",
    "    # data['millisUTC'] = pd.to_datetime(data['millisUTC'])\n",
    "    # data.set_index('millisUTC', inplace=True)\n",
    "\n",
    "    # # Resample dataset\n",
    "    # if resample_units is not None:\n",
    "    #     data = data.resample(resample_units, label=\"right\").mean()\n",
    "\n",
    "    # # Need a better way to handle missing values\n",
    "    # data['price'] = data['price'].ffill()\n",
    "    # data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    X, y = get_x_y_split(\n",
    "        data, \n",
    "        columns=columns, \n",
    "        targets=targets, \n",
    "        n_steps_in=n_steps_in, \n",
    "        n_steps_out=n_steps_out, \n",
    "        gap=gap, \n",
    "        include_target_in_X=include_target_in_X\n",
    "    )\n",
    "    \n",
    "    return {\"X\": X, \"y\": y}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fc00e91-9b46-4706-9604-6a4e0338ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=42):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    eval(\"setattr(torch.backends.cudnn, 'deterministic', True)\")\n",
    "    eval(\"setattr(torch.backends.cudnn, 'benchmark', False)\")\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "369f512c-4ace-4fb2-bb4f-86891e92d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(num_samples=None):\n",
    "    ds = ray.data.read_csv(DATASET_LOC)\n",
    "    ds = ds.random_shuffle(seed=1234)\n",
    "    ds = ray.data.from_items(ds.take(num_samples)) if num_samples else ds\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0d264df-609e-412d-b1fd-902f799eaf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPreprocessor(Preprocessor):\n",
    "    def _fit(self, ds):\n",
    "        return self\n",
    "\n",
    "    def _transform_pandas(self, batch):\n",
    "        return preprocess(\n",
    "            batch,\n",
    "            # resample_units=\"10T\", # Resample values by 60 minutes\n",
    "            columns=['price'],\n",
    "            targets=['price'], \n",
    "            n_steps_in=5, \n",
    "            n_steps_out=10, \n",
    "            gap=60, \n",
    "            include_target_in_X=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6aa0d11c-73de-4027-9767-93fb1a333574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    \"\"\"LSTM neural network\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, X, h=None):\n",
    "        X, _ = X['X'], X['y']\n",
    "        \n",
    "        if h is None:\n",
    "            h = (torch.zeros(1, X.size(0), 32).to(X.device),\n",
    "                 torch.zeros(1, X.size(0), 32).to(X.device))\n",
    "\n",
    "        print(f\"Type of X: {X.dtype}\")\n",
    "        \n",
    "        output, hidden_state = self.lstm(X, h)\n",
    "        last_hidden_state = output[:, -1, :]\n",
    "        output = self.linear(last_hidden_state)\n",
    "        output = F.relu(output)  # Apply ReLU activation\n",
    "        return output\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def predict(self, batch):\n",
    "        print(\"calling predict\")\n",
    "        print(\"SNAP\")\n",
    "        self.eval()\n",
    "        return self(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "283d7062-a693-4811-9a29-e6582995c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air import Checkpoint, session\n",
    "from ray.air.config import CheckpointConfig, DatasetConfig, RunConfig, ScalingConfig\n",
    "import ray.train as train\n",
    "from ray.train.torch import TorchCheckpoint, TorchTrainer\n",
    "import torch.nn.functional as F\n",
    "from ray.train.torch import get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9897136c-92a9-4139-b9fb-e9d91f0d2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    dtypes = {\"X\": torch.float32, \"y\": torch.float32}\n",
    "    tensor_batch = {}\n",
    "    for key, array in batch.items():\n",
    "        tensor_batch[key] = torch.as_tensor(array, dtype=dtypes[key], device=get_device())\n",
    "    return tensor_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e05f8729-30b0-4677-b8d7-ebed7a8a400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(ds, batch_size, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    loss = 0.0\n",
    "    ds_generator = ds.iter_torch_batches(batch_size=batch_size, collate_fn=collate_fn)\n",
    "    for i, batch in enumerate(ds_generator):\n",
    "        optimizer.zero_grad()  # reset gradients        \n",
    "        z = model(batch)  # forward pass\n",
    "        targets = batch['y']\n",
    "        J = loss_fn(z, targets)  # define loss\n",
    "        J.backward()  # backward pass\n",
    "        optimizer.step()  # update weights\n",
    "        loss += (J.detach().item() - loss) / (i + 1)  # cumulative loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "773a0cf8-a831-4856-9e37-d5cf3819f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(ds, batch_size, model, loss_fn):\n",
    "    \"\"\"Eval step.\"\"\"\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    y_trues, y_preds = [], []\n",
    "    ds_generator = ds.iter_torch_batches(batch_size=batch_size, collate_fn=collate_fn)\n",
    "    with torch.inference_mode():\n",
    "        for i, batch in enumerate(ds_generator):\n",
    "            z = model(batch)\n",
    "            targets = batch['y']\n",
    "            J = loss_fn(z, targets).item()\n",
    "            loss += (J - loss) / (i + 1)\n",
    "            y_trues.extend(batch[\"y\"].cpu().numpy())\n",
    "            y_preds.extend(torch.argmax(z, dim=1).cpu().numpy())\n",
    "    return loss, np.vstack(y_trues), np.vstack(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2119e891-d9d5-49e3-8d82-4223f0b2dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_loop_per_worker(config):\n",
    "    # Hyperparameters\n",
    "    dropout_p = config[\"dropout_p\"]\n",
    "    lr = config[\"lr\"]\n",
    "    lr_factor = config[\"lr_factor\"]\n",
    "    lr_patience = config[\"lr_patience\"]\n",
    "    num_epochs = config[\"num_epochs\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    input_size = config[\"input_size\"]\n",
    "    hidden_size = config[\"hidden_size\"]\n",
    "    output_size = config[\"output_size\"]\n",
    "\n",
    "    # Get datasets\n",
    "    set_seeds()\n",
    "    train_ds = session.get_dataset_shard(\"train\")\n",
    "    val_ds = session.get_dataset_shard(\"val\")\n",
    "\n",
    "    # Model\n",
    "    model =  LSTM(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
    "    model = train.torch.prepare_model(model)\n",
    "\n",
    "    # Training components\n",
    "    loss_fn = nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=lr_factor, patience=lr_patience)\n",
    "\n",
    "    # Training\n",
    "    batch_size_per_worker = batch_size // session.get_world_size()\n",
    "    for epoch in range(num_epochs):\n",
    "        # Step\n",
    "        train_loss = train_step(train_ds, batch_size_per_worker, model, loss_fn, optimizer)\n",
    "        val_loss, _, _ = eval_step(val_ds, batch_size_per_worker, model, loss_fn)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Checkpoint\n",
    "        metrics = dict(epoch=epoch, lr=optimizer.param_groups[0][\"lr\"], train_loss=train_loss, val_loss=val_loss)\n",
    "        checkpoint = TorchCheckpoint.from_model(model=model)\n",
    "        session.report(metrics, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2337434a-e483-454e-9552-f5223b634c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop config\n",
    "train_loop_config = {\n",
    "    \"dropout_p\": 0.5,\n",
    "    \"lr\": 1e-4,\n",
    "    \"lr_factor\": 0.8,\n",
    "    \"lr_patience\": 3,\n",
    "    \"num_epochs\": 1,\n",
    "    \"batch_size\": 256,\n",
    "    \"input_size\": 2,\n",
    "    \"hidden_size\": 32,\n",
    "    \"output_size\": 10\n",
    "}\n",
    "\n",
    "# Scaling config\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=num_workers,\n",
    "    use_gpu=bool(resources_per_worker[\"GPU\"]),\n",
    "    resources_per_worker=resources_per_worker,\n",
    "    _max_cpu_fraction_per_node=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cb46ee38-7f99-4959-aa55-60586bbb8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "    # Split the data into training and testing sets\n",
    "    train_size = int(0.8 * len(data))\n",
    "    train_data = data.iloc[:train_size]\n",
    "    test_data = data.iloc[train_size:]\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de10cfe2-c909-41e5-8d24-cbaaa300aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/ankushgarg/Desktop/projects/comed-pricing/data/raw_data.csv\")\n",
    "# This is a bit strange to do\n",
    "# We're reading the dataset using pandas, then splitting it, and then creating distributed datasets from pandas\n",
    "train_data, val_data = split_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a9b56fff-aa74-49e9-8f04-1d62ac0282f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ray.data.from_pandas(train_data)\n",
    "val_ds = ray.data.from_pandas(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "19d20960-ff21-473d-81d3-7efc6d84d52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 11:12:25,208\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(CustomPreprocessor._transform_pandas)]\n",
      "2023-09-06 11:12:25,209\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-06 11:12:25,210\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2023-09-06 11:12:25,355\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(CustomPreprocessor._transform_pandas)]\n",
      "2023-09-06 11:12:25,356\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-06 11:12:25,356\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    }
   ],
   "source": [
    "# Preprocess\n",
    "preprocessor = CustomPreprocessor()\n",
    "train_ds =  preprocessor.fit_transform(train_ds)\n",
    "val_ds = preprocessor.transform(val_ds)\n",
    "train_ds = train_ds.materialize()\n",
    "val_ds = val_ds.materialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7481b42f-0b1b-45be-a256-5b7adeec5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset config\n",
    "dataset_config = {\n",
    "    \"train\": DatasetConfig(fit=False, transform=False, randomize_block_order=False),\n",
    "    \"val\": DatasetConfig(fit=False, transform=False, randomize_block_order=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c6284-0b51-4b62-9298-2874e240a4e8",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c24ac710-e108-49e7-97eb-b665d0d4be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from pathlib import Path\n",
    "from ray.air.integrations.mlflow import MLflowLoggerCallback\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5a803b2c-4f45-4988-98b0-fc59a6631e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:///tmp/mlflow\n"
     ]
    }
   ],
   "source": [
    "# Config MLflow\n",
    "MODEL_REGISTRY = Path(\"/tmp/mlflow\")\n",
    "Path(MODEL_REGISTRY).mkdir(parents=True, exist_ok=True)\n",
    "MLFLOW_TRACKING_URI = \"file://\" + str(MODEL_REGISTRY.absolute())\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "print(mlflow.get_tracking_uri())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b909e056-3614-4866-9256-e03e55b5089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow callback\n",
    "experiment_name = f\"comed-{int(time.time())}\"\n",
    "mlflow_callback = MLflowLoggerCallback(\n",
    "    tracking_uri=MLFLOW_TRACKING_URI,\n",
    "    experiment_name=experiment_name,\n",
    "    save_artifact=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "31d69cdb-0a25-4f8d-8af8-563382bf4356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 11:12:27,536\tWARNING data_parallel_trainer.py:278 -- The dict form of `dataset_config` is deprecated. Use the DataConfig class instead. Support for this will be dropped in a future release.\n",
      "2023-09-06 11:12:27,539\tWARNING base_trainer.py:205 -- The `preprocessor` arg to Trainer is deprecated. Apply preprocessor transformations ahead of time by calling `preprocessor.transform(ds)`. Support for the preprocessor arg will be dropped in a future release.\n"
     ]
    }
   ],
   "source": [
    "# Trainer\n",
    "checkpoint_config = CheckpointConfig(num_to_keep=1, checkpoint_score_attribute=\"val_loss\", checkpoint_score_order=\"min\")\n",
    "\n",
    "# Run configuration with MLflow callback\n",
    "run_config = RunConfig(\n",
    "    callbacks=[mlflow_callback],\n",
    "    checkpoint_config=checkpoint_config,\n",
    ")\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config=train_loop_config,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    "    datasets={\"train\": train_ds, \"val\": val_ds},\n",
    "    dataset_config=dataset_config,\n",
    "    preprocessor=preprocessor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "71da747d-809e-439f-b47a-6ebdcc721c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-09-06 11:12:36</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:07.89        </td></tr>\n",
       "<tr><td>Memory:      </td><td>17.9/32.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 7.0/10 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_2caf8_00000</td><td>TERMINATED</td><td>127.0.0.1:86546</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.14249</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     3.20721</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=86546)\u001b[0m The dict form of `dataset_config` is deprecated. Use the DataConfig class instead. Support for this will be dropped in a future release.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=86546)\u001b[0m The `preprocessor` arg to Trainer is deprecated. Apply preprocessor transformations ahead of time by calling `preprocessor.transform(ds)`. Support for the preprocessor arg will be dropped in a future release.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=86546)\u001b[0m Starting distributed worker processes: ['86550 (127.0.0.1)', '86551 (127.0.0.1)', '86552 (127.0.0.1)', '86553 (127.0.0.1)', '86554 (127.0.0.1)', '86555 (127.0.0.1)']\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=86550)\u001b[0m Setting up process group for: env:// [rank=0, world_size=6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=86555)\u001b[0m Type of X: torch.float32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=86555)\u001b[0m Type of X: torch.float32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=86555)\u001b[0m Type of X: torch.float32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=86555)\u001b[0m Type of X: torch.float32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=86555)\u001b[0m Type of X: torch.float32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=86553)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=86553)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=86550)\u001b[0m Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=86550)\u001b[0m Wrapping provided model in DistributedDataParallel.\n",
      "2023-09-06 11:12:36,067\tINFO tune.py:1148 -- Total run time: 7.90 seconds (7.89 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "results = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1dc153bd-7133-49ec-bd6d-df787a68c4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>metrics.config/train_loop_config/lr_patience</th>\n",
       "      <th>metrics.train_loss</th>\n",
       "      <th>metrics.config/train_loop_config/batch_size</th>\n",
       "      <th>metrics.time_this_iter_s</th>\n",
       "      <th>...</th>\n",
       "      <th>params.train_loop_config/input_size</th>\n",
       "      <th>params.train_loop_config/batch_size</th>\n",
       "      <th>params.train_loop_config/lr</th>\n",
       "      <th>params.train_loop_config/num_epochs</th>\n",
       "      <th>params.train_loop_config/dropout_p</th>\n",
       "      <th>params.train_loop_config/lr_factor</th>\n",
       "      <th>params.train_loop_config/lr_patience</th>\n",
       "      <th>params.train_loop_config/output_size</th>\n",
       "      <th>tags.trial_name</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9dc915d0ed2d4cdab2d8a53f4828f606</td>\n",
       "      <td>767405631797657633</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>file:///tmp/mlflow/767405631797657633/9dc915d0...</td>\n",
       "      <td>2023-09-06 16:12:29.822000+00:00</td>\n",
       "      <td>2023-09-06 16:12:36.060000+00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.207213</td>\n",
       "      <td>256.0</td>\n",
       "      <td>4.142494</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>TorchTrainer_2caf8_00000</td>\n",
       "      <td>TorchTrainer_2caf8_00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id       experiment_id    status  \\\n",
       "0  9dc915d0ed2d4cdab2d8a53f4828f606  767405631797657633  FINISHED   \n",
       "\n",
       "                                        artifact_uri  \\\n",
       "0  file:///tmp/mlflow/767405631797657633/9dc915d0...   \n",
       "\n",
       "                        start_time                         end_time  \\\n",
       "0 2023-09-06 16:12:29.822000+00:00 2023-09-06 16:12:36.060000+00:00   \n",
       "\n",
       "   metrics.config/train_loop_config/lr_patience  metrics.train_loss  \\\n",
       "0                                           3.0            3.207213   \n",
       "\n",
       "   metrics.config/train_loop_config/batch_size  metrics.time_this_iter_s  ...  \\\n",
       "0                                        256.0                  4.142494  ...   \n",
       "\n",
       "   params.train_loop_config/input_size  params.train_loop_config/batch_size  \\\n",
       "0                                    2                                  256   \n",
       "\n",
       "   params.train_loop_config/lr  params.train_loop_config/num_epochs  \\\n",
       "0                       0.0001                                    1   \n",
       "\n",
       "   params.train_loop_config/dropout_p  params.train_loop_config/lr_factor  \\\n",
       "0                                 0.5                                 0.8   \n",
       "\n",
       "   params.train_loop_config/lr_patience  params.train_loop_config/output_size  \\\n",
       "0                                     3                                    10   \n",
       "\n",
       "            tags.trial_name       tags.mlflow.runName  \n",
       "0  TorchTrainer_2caf8_00000  TorchTrainer_2caf8_00000  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorted runs\n",
    "sorted_runs = mlflow.search_runs(experiment_names=[experiment_name], order_by=[\"metrics.train_loss ASC\"])\n",
    "sorted_runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b42bbf50-6ba8-4538-a7a6-d90ce736ef1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9dc915d0ed2d4cdab2d8a53f4828f606'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorted runs\n",
    "sorted_runs = mlflow.search_runs(experiment_names=[experiment_name], order_by=[\"metrics.val_loss ASC\"])\n",
    "sorted_runs['run_id'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "25803fa8-42b2-41e5-8f4e-5a45680cda7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 12:14:10,403\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(CustomPreprocessor._transform_pandas)]\n",
      "2023-09-06 12:14:10,403\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-06 12:14:10,404\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'X': array([[2.1, 2.1],\n",
       "         [2.2, 2.2],\n",
       "         [2.4, 2.4],\n",
       "         [2.2, 2.2],\n",
       "         [2.3, 2.3]], dtype=float32),\n",
       "  'y': array([2.9, 2.6, 2.6, 3. , 2.9, 2.9, 2.9, 2.5, 2.5, 2.5], dtype=float32)}]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.train.torch import TorchPredictor\n",
    "\n",
    "best_checkpoint = results.best_checkpoints[0][0]\n",
    "predictor = TorchPredictor.from_checkpoint(best_checkpoint)\n",
    "preprocessor = predictor.get_preprocessor()\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(HOLDOUT_LOC, dtype=\"float32\")\n",
    "test_ds = ray.data.from_pandas(test_df)\n",
    "preprocessed_ds = preprocessor.transform(test_ds)\n",
    "preprocessed_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c8225781-1044-4d5d-978e-6a77a7a83d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 11:12:36,243\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadCSV->SplitBlocks(20)] -> TaskPoolMapOperator[MapBatches(CustomPreprocessor._transform_pandas)->MapBatches(<lambda>)]\n",
      "2023-09-06 11:12:36,244\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-06 11:12:36,244\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    }
   ],
   "source": [
    "# y_true\n",
    "values = preprocessed_ds.select_columns(cols=[\"y\"]).take_all()\n",
    "y_true = np.stack([item[\"y\"] for item in values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "79e89ce3-0db7-4372-b3f9-033b707a4f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of X: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# y_pred\n",
    "y_pred = predictor.predict(test_ds.to_pandas())[\"predictions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e3d25513-944e-4588-8fd9-5f1a7c0342a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.data\n",
    "from ray.train.torch import TorchPredictor\n",
    "from ray.data import ActorPoolStrategy\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, checkpoint):\n",
    "        self.predictor = TorchPredictor.from_checkpoint(checkpoint)\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        z = self.predictor.predict(batch)[\"predictions\"]\n",
    "        y_pred = np.stack(z)\n",
    "        return {\"prediction\": y_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ed6f4730-addf-4951-82d2-96df5f4e4f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch predict\n",
    "predictions = test_ds.map_batches(\n",
    "    Predictor,\n",
    "    batch_size=128,\n",
    "    compute=ActorPoolStrategy(min_size=1, max_size=2),  # scaling\n",
    "    batch_format=\"pandas\",\n",
    "    fn_constructor_kwargs={\"checkpoint\": best_checkpoint})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a571e64c-b00a-44ec-89fc-89098a6f4ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 12:15:07,489\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[MapBatches(Predictor)]\n",
      "2023-09-06 12:15:07,490\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-06 12:15:07,491\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2023-09-06 12:15:07,517\tINFO actor_pool_map_operator.py:117 -- MapBatches(Predictor): Waiting for 1 pool actors to start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MapWorker(MapBatches(Predictor)) pid=90331)\u001b[0m Type of X: torch.float32\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prediction': array([0.34149176, 0.3253997 , 0.34754878, 0.        , 0.        ,\n",
       "         0.46825808, 0.        , 0.        , 0.5945572 , 0.80085206],\n",
       "        dtype=float32)},\n",
       " {'prediction': array([0.34712058, 0.33643743, 0.35290688, 0.        , 0.        ,\n",
       "         0.4759032 , 0.        , 0.        , 0.60753024, 0.8126106 ],\n",
       "        dtype=float32)},\n",
       " {'prediction': array([0.34332034, 0.3337593 , 0.35338175, 0.        , 0.        ,\n",
       "         0.4740445 , 0.        , 0.        , 0.6021232 , 0.8105459 ],\n",
       "        dtype=float32)}]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016df1f3-33b8-4455-b385-87365a69c40b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
